{
    "0": "1\n \nOverview of Text Retrieval Methods\n \n \nChengXiang\n \n\n \nDepartment of Computer Science\n \nUniversity of Illinois at Urbana\n-\nChampaign\n \n \n",
    "1": "Overview of Text Retrieval Methods\n \n2\n \n",
    "2": "How to Design a Ranking Function\n \n\nQuery:\n \nq = q\n1\n\nq\nm\n,\n \nwhere q\ni \n\n \nV\n \n\nDocument: \nd = d\n1\n\nd\nn\n,\n \nwhere d\ni \n\n \nV\n \n\nRanking function: \nf(q,\n \nd) \n\n \n\nA good ranking function should rank relevant documents \non top of non\n-\nrelevant ones\n \n\nKey challenge: how to measure the likelihood that \ndocument d is \nrelevant\n \nto query q\n \n\nRetrieval model \n= formalization of relevance (give a \ncomputational\n \ndefinition of relevance) \n \n \n3\n \n",
    "3": "Many Different Retrieval Models\n \n\nSimilarity\n-\nbased models\n: f(\nq,d\n) = similarity(\nq,d\n)\n \n\nVector space model \n \n\nProbabilistic models\n: f(\nd,q\n) = p(R=1|d,q), where R \n\n{0,1} \n \n\nClassic probabilistic model \n \n\nLanguage model \n \n\nDivergence\n-\nfrom\n-\nrandomness model\n \n\nProbabilistic inference model\n: f(\nq,d\n) = p(\nd\n\nq\n)\n \n\nAxiomatic model\n: f(\nq,d\n) must satisfy a set of constraints\n \n\nThese \ndifferent models tend to result in \nsimilar \nranking \nfunctions \ninvolving \nsimilar variables  \n \n \n \n4\n \n",
    "4": "5\n \nCommon Ideas in State of the Art Retrieval Models\n \n\npresidential\n \ncampaign\n \nnews\n\n \ng\n\npresidential\n\n \ng\n\ncampaign\n\n \ng\n\nnews\n\n \nHow long is d?        \nDocument length\n:    |d| \n \n\npresidential\n\n \n        \nDocument Frequency\n:  \ndf\n\npresidential\n\n \n        \n\npresidential\n\n) \n \n \n\npresidential\n\n \n         \nTerm Frequency \n\npresidential\n\n \n\n \n",
    "5": "Which Model \nW\norks the Best? \n \n\nWhen optimized, the following models tend to perform \nequally well [Fang  et al. 11]: \n \n\nPivoted length normalization\n \n\nBM25\n \n\nQuery likelihood\n \n\nPL2\n \n\nBM25 is most popular\n \n6\n \n",
    "6": "Summary\n \n\nDesign of ranking function\n \nf(\nq,d\n) \npre\n-\nrequires a \ncomputational definition of relevance (retrieval model)\n \n\nMany models are equally effective with no single winner \n \n \n\nState of the art ranking functions tend to rely on\n \n\nBag of words representation\n \n\nTerm Frequency (TF) and Document Frequency (DF) of words \n \n\nDocument length\n \n \n7\n \n",
    "7": "Additional Readings\n \n\nDetailed discussion and comparison of state of the art \nmodels\n \n\nHui \nFang, Tao Tao, and \nChengxiang\n \nZhai\n. 2011. Diagnostic \nEvaluation of Information Retrieval Models. \nACM Trans. Inf. \nSyst.\n \n29, 2, Article 7 (April 2011\n)\n \n \n\nBroad review of different retrieval models \n \n\nChengXiang\n \nZhai\n, \nStatistical Language Models for Information \nRetrieval \n, Morgan & Claypool \nPublishers\n,  \n2008. (Chapter 2) \n \n \n \n \n \n8\n \n"
}